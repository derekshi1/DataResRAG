{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['course-descriptions-combined', 'course-descriptions', 'course-embeddings']\n"
     ]
    }
   ],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=\"pcsk_2uKCF8_5LSz4hbio5WP681G6ThuJp3vBDxx7tuWSrM2RXrviFnwe7LmvEB5YVDGmm3mN5w\")\n",
    "\n",
    "# To get the unique host for an index, \n",
    "# see https://docs.pinecone.io/guides/data/target-an-index\n",
    "\n",
    "print(pc.list_indexes().names())\n",
    "index = pc.Index(\"course-descriptions-combined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HerryLiu/anaconda3/envs/CS145.1/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/HerryLiu/anaconda3/envs/CS145.1/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <5AA8DD3D-A2CC-31CA-8060-88B4E9C18B09> /Users/HerryLiu/anaconda3/envs/CS145.1/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <EEB3232B-F6A7-3262-948C-BB2F54905803> /Users/HerryLiu/anaconda3/envs/CS145.1/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/HerryLiu/anaconda3/envs/CS145.1/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/HerryLiu/anaconda3/envs/CS145.1/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def pinecone_search(query):\n",
    "    # Function to create embeddings for a course description\n",
    "    def get_embedding(text):\n",
    "        return model.encode(text)\n",
    "    # Convert the query into a numerical vector that Pinecone can search with\n",
    "\n",
    "\n",
    "    query_embedding = get_embedding(query)\n",
    "\n",
    "    # Search the index for the three most similar vectors\n",
    "    results = index.query(\n",
    "        namespace=\"\",\n",
    "        vector=query_embedding,\n",
    "        top_k=5,\n",
    "        include_values=True,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_context_and_query(query,results):\n",
    "    # Extract metadata and format for LLM input\n",
    "    context = \"\"\n",
    "    for match in results['matches']:\n",
    "        course_id = match['id']\n",
    "        category = match['metadata']['category']\n",
    "        description = match['metadata']['description']\n",
    "        sequence = match['metadata']['sequence']\n",
    "        \n",
    "        # You can choose which fields to include in the context\n",
    "        context += f\"\"\"\n",
    "        Course ID: {course_id}\n",
    "        Category: {category}\n",
    "        Description: {description}\n",
    "        Sequence: {sequence}\n",
    "        \"\"\"\n",
    "    query_text = query\n",
    "    # Combine the context with the query for the LLM\n",
    "    input_text = f\"\"\"\n",
    "    Based on the following course details, answer the question in a detailed and informative manner.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Question: {query_text}\n",
    "    \"\"\"\n",
    "    return input_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(api_key=\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(context, user_query):\n",
    "    # print(context)\n",
    "    # print(user_query)\n",
    "    prompt =  context + user_query\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"\n",
    "         You are a helpful course planning assistant. In a minute, the user will feed you a \n",
    "         query about courses at UCLA for the data theory major and some context about the courses,\n",
    "        and you will give them useful advice about which to choose, the difficulty, prequisites, and any other useful information.\n",
    "         \n",
    "         \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"Qwen/Qwen2.5-72B-Instruct\", \n",
    "        messages=messages, \n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    return completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae44d54d2e749baba0659bf14462416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Question:', layout=Layout(height='auto', min_height='100px', width='60%'), pla…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a89a0ca5dd34f8888544116e1dec3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Submit', layout=Layout(width='20%'), style=ButtonStyle(), tooltip=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9147ba77154daca617941ffcef2e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(min_height='150px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "# Create a simple UI for input and output\n",
    "input_box = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Ask your question...',\n",
    "    description='Question:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(\n",
    "        width='60%',\n",
    "        height='auto',  # Allow auto resizing based on content\n",
    "        min_height='100px',  # Minimum height in case of no content\n",
    "        overflow_y='auto'\n",
    "    )\n",
    ")\n",
    "\n",
    "submit_button = widgets.Button(\n",
    "    description='Submit',\n",
    "    button_style='success',  \n",
    "    tooltip='Click to submit your query',\n",
    "    layout=widgets.Layout(width='20%')\n",
    ")\n",
    "\n",
    "output_box = widgets.Output(\n",
    "    layout=widgets.Layout(\n",
    "        width='100%',\n",
    "        min_height='150px',  # Set a minimum height for the output box\n",
    "        overflow_y='auto'  # Ensure scrolling if content overflows\n",
    "    )\n",
    ")\n",
    "\n",
    "loading_indicator = widgets.HTML(\n",
    "    value=\"<div style='text-align:center;'><b>Loading...</b><br><img src='https://i.imgur.com/llF5iyg.gif' width='50'></div>\",\n",
    "    layout=widgets.Layout(width='100%'),\n",
    "    visible=False\n",
    ")\n",
    "\n",
    "# Markdown output box (styled)\n",
    "markdown_output_box = widgets.Output(\n",
    "    layout=widgets.Layout(\n",
    "        width='100%',\n",
    "        min_height='150px',\n",
    "        overflow_y='auto',\n",
    "        padding='10px',\n",
    "        border='1px solid #ccc',\n",
    "        background_color='#f9f9f9',\n",
    "        border_radius='5px',\n",
    "        box_shadow='0px 0px 5px rgba(0, 0, 0, 0.1)'\n",
    "    )\n",
    ")\n",
    "# Function to handle user input when the submit button is clicked\n",
    "def on_submit_button_clicked(b):\n",
    "    with output_box:\n",
    "        # Show the loading spinner\n",
    "        loading_indicator.visible = True\n",
    "        display(loading_indicator)\n",
    "        \n",
    "        user_query = input_box.value\n",
    "        \n",
    "        # Step 1: Get context from the vector database (Pinecone)\n",
    "        context = pinecone_search(user_query)  # This is your function to get context\n",
    "        \n",
    "        # Step 2: Process context and user query\n",
    "        processed_context = process_context_and_query(user_query, context)\n",
    "        \n",
    "        # Step 3: Generate a response from the LLM\n",
    "        response = generate_response(processed_context, user_query)  # This is your function to generate response\n",
    "        \n",
    "        # Clear the output box before displaying the new response\n",
    "        output_box.clear_output(wait=True)\n",
    "        \n",
    "        # Hide the loading indicator\n",
    "        loading_indicator.visible = False\n",
    "        \n",
    "        # Display the assistant's response in markdown format\n",
    "        display(Markdown(response['choices'][0]['message'][\"content\"]))\n",
    "\n",
    "# Attach the function to the button\n",
    "submit_button.on_click(on_submit_button_clicked)\n",
    "\n",
    "# Display the input, submit button, and output widgets\n",
    "display(input_box, submit_button, output_box)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS145.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
